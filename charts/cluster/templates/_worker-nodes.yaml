{{- define "cluster.worker-nodes" -}}
{{- $networking := (include "networking" .) | fromYaml }}
{{- $machines := (include "machines" .) | fromYaml }}
{{- if eq .Values.capi.providers.infrastructure.name "hetzner" }}
---
{{/*
https://syself.com/docs/caph/reference/hcloud-machine-template
*/}}
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: HCloudMachineTemplate
metadata:
  name: {{ include "worker-hcloud-machine-template-name" . }}
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "cluster.labels" . | nindent 4 }}
    {{- include "worker-hcloud-machine-template-labels" . | nindent 4 }}
  annotations:
    argocd.argoproj.io/sync-wave: "-5"
spec:
  template:
    spec: {{- include "worker-hcloud-machine-template-spec" . | nindent 6 }}
{{- end }}
{{- if eq .Values.capi.providers.bootstrap.name "talos" }}
---
apiVersion: bootstrap.cluster.x-k8s.io/v1alpha3
kind: TalosConfigTemplate
metadata:
  name: {{ include "worker-name" . }}
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "cluster.labels" . | nindent 4 }}
spec:
  template:
    spec:
      strategicPatches:
      # https://www.talos.dev/v1.8/talos-guides/install/cloud-platforms/hetzner/#install-hetzners-cloud-controller-manager
      - |
        cluster:
          externalCloudProvider:
            enabled: true
      # https://www.talos.dev/v1.8/kubernetes-guides/network/deploying-cilium/#machine-config-preparation
      - |
        cluster:
          network:
            cni:
              name: none
          proxy:
            disabled: true
      # https://www.talos.dev/v1.8/talos-guides/network/kubespan/#creating-a-new-cluster
      # https://www.talos.dev/v1.8/talos-guides/network/kubespan/#configuration
      # Hcloud has a MTU of 1450 (KubeSpanMTU = UnderlyingMTU - 80)
      # - |
      #   machine:
      #     network:
      #       kubespan:
      #         enabled: true
      #         advertiseKubernetesNetworks: false
      #         allowDownPeerBypass: false
      #         mtu: 1370
      # - |
      #   cluster:
      #       discovery:
      #           enabled: true
      #           # Configure registries used for cluster member discovery.
      #           registries:
      #               kubernetes: # Kubernetes registry is problematic with KubeSpan, if the control plane endpoint is routeable itself via KubeSpan.
      #                 disabled: true
      #               service: {}
      # https://github.com/siderolabs/talos-cloud-controller-manager/blob/main/docs/install.md#prepare-nodes
      - |
        machine:
          kubelet:
            extraArgs:
              cloud-provider: external
              # For security reasons, it is recommended to enable the rotation of server certificates.
              rotate-server-certificates: true
      - |
        machine:
          install:
            image: ghcr.io/siderolabs/installer:{{ $machines.worker.osVersion }}
            extraKernelArgs:
              - "ipv6.disable=1"
          {{- with .Values.hCloud.lb.existing.ip }}
          certSANs:
          - {{ . | quote }}
          {{- end }}
          network:
            # extraHostEntries:
            interfaces:
            - interface: eth0
              dhcp: true
          # sysctls:
          #   net.core.somaxconn: "65535"
          #   net.core.netdev_max_backlog: "4096"
          features:
            hostDNS:
          #     enabled: true
          #     forwardKubeDNSToHost: true
              resolveMemberNames: true
          # time:
          #   servers:
          #   - "ntp1.hetzner.de"
          #   - "ntp2.hetzner.com"
          #   - "ntp3.hetzner.net"
          #   - "time.cloudflare.com"
          # RegistriesConfig represents the image pull options.
          # registries:
          {{- if $networking.hcloudNetworkEnabled }}
          kubelet:
            nodeIP:
              validSubnets:
              - "{{ $networking.subnetIpv4Cidr }}"
          {{- end }}
        cluster:
          network:
            dnsDomain: cluster.local
            podSubnets:
              - "{{ $networking.podsIpv4Cidr }}"
            serviceSubnets:
              - "{{ $networking.servicesIpv4Cidr }}"
      {{- with .Values.talos.machine.registries.mirrors }}
      - |
        machine:
          registries:
            mirrors:
              {{- . | toYaml | nindent 14 }}
      {{- end }}
      generateType: worker
      # When we set this, there were errors with certificate signing requests for node (it was using wrong DNS names).
      # hostname:
      #   source: "MachineName"
      talosVersion: {{ $machines.worker.osVersion }}
{{- else if eq .Values.capi.providers.bootstrap.name "kubeadm" }}
---
apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
kind: KubeadmConfigTemplate
metadata:
  name: {{ include "worker-kubeadm-config-template-name" . }}
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "cluster.labels" . | nindent 4 }}
spec:
  template:
    {{- /*
    # https://cluster-api.sigs.k8s.io/tasks/bootstrap/kubeadm-bootstrap/#kubeadmconfig-objects
    # https://kubernetes.io/docs/reference/config-api/kubeadm-config.v1beta3/
    # k explain KubeadmConfigTemplate.spec.template.spec
    # NOTE: KubeadmConfigTemplate.spec.template.spec = KubeadmControlPlane.spec.kubeadmConfigSpec
    */}}
    spec: {{- include "worker-kubeadm-config-template-spec" . | nindent 6 }}
{{- end }}
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: MachineDeployment
metadata:
  name: {{ include "worker-name" . }}
  namespace: {{ .Release.Namespace }}
  labels:
    nodepool: {{ include "worker-name" . }}
    {{- include "cluster.labels" . | nindent 4 }}
  {{- if $machines.worker.autoscaler.enabled }}
  annotations:
    cluster.x-k8s.io/cluster-api-autoscaler-enabled: "true"
    cluster.x-k8s.io/cluster-api-autoscaler-node-group-min-size: "{{ $machines.worker.autoscaler.minSize }}"
    cluster.x-k8s.io/cluster-api-autoscaler-node-group-max-size: "{{ $machines.worker.autoscaler.maxSize }}"
  {{- end }}
spec:
  clusterName: {{ include "cluster-name" . }}
  replicas: {{ $machines.worker.replicas }}
  selector:
    matchLabels:
      nodepool: {{ include "worker-name" . }}
      # cluster.x-k8s.io/cluster-name: {{ include "cluster-name" . }}
  {{- /*
  # strategy:
  #   remediation:
  #   type: RollingUpdate
  #   rollingUpdate:
  #     deletePolicy:
  #     maxSurge:
  #     maxUnavailable:
  */}}
  template:
    metadata:
      labels:
        nodepool: {{ include "worker-name" . }}
        # cluster.x-k8s.io/cluster-name: {{ include "cluster-name" . }}
    spec:
      bootstrap:
        configRef:
          {{- if eq .Values.capi.providers.bootstrap.name "talos" }}
          apiVersion: bootstrap.cluster.x-k8s.io/v1alpha3
          kind: TalosConfigTemplate
          name: {{ include "worker-name" . }}
          {{- else if eq .Values.capi.providers.bootstrap.name "kubeadm" }}
          apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
          kind: KubeadmConfigTemplate
          name: {{ include "worker-kubeadm-config-template-name" . }}
          {{- end }}
          namespace: {{ .Release.Namespace }}
      clusterName: {{ include "cluster-name" . }}
      failureDomain: {{ $networking.region }}
      infrastructureRef:
        {{- if eq .Values.capi.providers.infrastructure.name "hetzner" }}
        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
        kind: HCloudMachineTemplate
        {{- end }}
        name: {{ include "worker-hcloud-machine-template-name" . }}
        namespace: {{ .Release.Namespace }}
      version: {{ $machines.worker.k8sVersion }}
{{- end -}}
